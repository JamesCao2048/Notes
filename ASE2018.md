# ASE2018
## Is this class thread-safe? inferring documentation using graph-based learning
### Topic: Performance
### Motivation
- 问题：很多class的文档中没有说明该class是否为`线程安全`，这导致程序员在编程时必须考察其具体实现细节来同步所有对它的访问，或者乐观地假定其为线程安全的。
  - 未声明是否线程安全时，不知道是缺失还是线程安全。
  - 考察具体细节会破坏class的封装
  - 同步所有访问，以防止data races, atomicity violations, deadlocks等并发bug，会降低performance
  - 乐观假定class为线程安全会导致并发bug,很难dbug因为只有在特定interleaving的情况下才能发现
- 解决：本文提出了`TSFinder`，自动将class分类为线程安全或线程不安全。主要思路是使用轻量级代码静态分析，从class中提取graph representation，然后利用graph representation 训练classifier。
  - 轻量级代码静态分析并抽取graph representation技术
  - graph based classsification: SVM+graph kernels
- 结果：在之前未见过的class上达到94.5%的准确率，每个class分类用时3秒。
- 前人对并发bug的研究集中于寻找可能成为`bug`的cornor case,而本文使用自动化方法并且生成`documentation`

### Concepts
- 线程安全类(Thread-safe class): 封装好所有实例被并发访问时需要的同步方法，而无需用户再去做额外的同步操作。
- Graph kernel: 用来计算两个图之间相似度的数学函数。

### Challenges
- Efficient. 需要很快处理某个第三方library的数百个class
- Reliable.困难在于：
  - 保证线程安全的方法很多，包括making the class immutable, using language-level synchronization primitives, building on other thread-safe classes, using lock-free data structures,以及这些方法的组合，所以一次简单的检查很难覆盖到这么多方法。
  - 一个class是否线程安全可能取决于其他class，包括继承等。
  - 枚举所有的interleaving会占用很多计算资源
### Methods
- Graph Representation Extraction.
  - 由于并发问题往往出现在对shared resources的访问使用上，因此graph表示这些资源如何被使用的。
  - 每个变量对应一个graph，来描述其是如何被读写的，以及一些修饰符的声明等。
- Computing graph kernels. `Graph kernel`用来计算两个图之间相似度的数学函数。最后得到`graph vector or embedding`来表示相似度
- Learning a classification model. Combine all graph vector into a single vector, called `class vector`, that represents the entire class.
- Classifying a new class. 获得new class的class vector并进行分类。

### Evaluation
- Validate existing classes lack thread safety documentation: 从`Qualitas corpus`中`系统搜索`(什么意思？)到179239个class，发现大部分缺乏相关文档。
  - 只关注`java doc comments`形式提供的文档，而忽略其他网站的文档，书籍等
  - 先使用java doc工具生成HTML，再根据关键词检索，"concu", "thread", "sync", "parallel"。179239个类中有8655个包含上述关键词
  - 从8655个类中随机取样120个，人工检查并将其分为四类。最终结果是只有1%的class有thread documentation.
    - Documented as thread-safe
    - Documented as thread-unsafe
    - Documented as conditionally thread-safe
    - No documentation(79.2%)
- Effectiveness of TSFinder. 从jdk1.8中收集了230个有thread documentation的class。使用人工标记的230个trainning classes来评估classifier。
  - 10 fold cross validation
  - 甚至发能现错误的文档并进行纠正
- Efficiency of TSFinder。训练时间，判断时间，内存占用
- Comparision with Alternative Approaches.
  - WL Graph Kervel
  - Classification Algorithm
  - Simple Classifier

### 思考
- 文章的motivation非常有用，并且有充分的论证。只是结果的实验集比较小，只有230的1/10(Limitation中也进行了说明)，不足以覆盖所有的thread-safe以及thread-unsafe的pattern。
- 实验部分从motivation的必要性，算法的有效性及效率，替代算法等等进行了全面的实验，值得学习。
- 静态分析将代码转换为图结构描述的想法或许能用到其他class-level propeties上，比如`immutability`,或者判断code是否里有某一种类型的bug。
- 代码静态分析后，能否通过自定义规则的方式来判断class是否线程安全？
- 如何编写一个thread-safe class？
### Related Work
- Analysis of Concurrent Code
- API Documentation
- `Specification Mining`
  - 从源代码或者程序执行中自动提取出正式的specification。包括:
    - finite-state specifications of method calls
    - algebraic specifications
    - temporal specifications of API usages
    - `implicit programming rules`. PR-Miner: Automatically Extracting Implicit Programming Rules and Detecting Violations in Large Software Code.
    - `locking disciplines`. Locking discipline inference and checking
- Graph kernel
  - analyze process trees to identify malware
## Automated directed fairness testing
### Topic: Quality Assurance for Machine Learning Techniques
### Motivation
- 问题：在`decision-making`中，`公平性`非常重要。但是如何去验证任意机器学习方法的公平性？
- 解决：给定一个机器学习模型，和一组敏感的输入特征，提出AEQUITAS来自动发现可能导致不公平的输入特征。
  - 可以系统地加入模型的训练集并且改善其公平性。Test generation to retrain model
  - 公开了实验数据(https://github.com/sakshiudeshi/Aequitas)

### Concepts
- Nondiscrimination: The basic idead behind non-discrimination is to eliminate any societal bias based on sensitive attributes, such as race, gender or religion. 
- Individual fairness: 两个个体对于同一份工作应该被以一种相似的方式对待。
- Discriminatory inputs: 对于一个机器学习模型，可能通过系统搜索其输入空间来发现可能会造成discrimination的输入特征。

### Challenges
- 可能损害individual fairness的input feature可能只存在于特定输入空间的区域，因此需要快速定位到这些输入区域。
- 一个简单地让模型公平的方法是去掉这些`sensitive features`，但这会由于blindness而失败。因为模型很可能通过输入的信息冗余来推测出去除掉的sensitive features。
- 公平性测试与传统软件测试的区别：
  - 模型通常被部署在缺少正式描述的功能情景中。
  - 可以通过更改输入数据，重新训练机器学习模型而不是修改代码来改善软件
- 相比于已有的工作，本文专注于生成test的策略

### Methods
- Global search. Uniformly sample the inputs and record the discriminatory inputs. 至少能找到一个discriminary input，如果存在的话。
- Local search. Discriminary input I附近可能存在更多的discriminary input. 
- Estimation of discriminatory inputs. 利用`大数定理`来预测discriminatory inputs可能的比例
- Why AEQUITAS works. 原因在于机器学习模型的相对`鲁棒性`，即输入稍微更改后不会对结果造成明显的影响。这样就可以从已有的discriminatroy inputs获得更多的可能候选者。
### Evaluations
- Setup: 
  - 一个特意被设计为fair的classifier，其他的classifier为python scikit-learn机器学习library(SVM, MLPC, Random Forest以及Decision Tree)。同时也进行了ensemble模型的测试。
  - 使用来自`US census`的数据，数据集大小32000左右。目标函数式分出收入在50000美元以上的人。
- Results:
  - AEQUITAS fully-directed比semi-directed以及无directed效果好，但需要更多计算资源
  - 比state-of-art的random tesing效果好
  - 生成的测试输入可以改善模型的公平性
### 思考
- 当discriminayive feature确实能起到非常重要的分类效果时，应该怎么办？

## Characterizing the natural language descriptions in software logging statements
### Topic: Mining and Crowd Sourcing
### Motivation
- 问题：程序的log对于软件维护，故障分析非常重要，但是现在没有一个对于应该如何在log中加入描述性语言的Guide。
- 解决方案：本文系统分析了开发者们log了什么，主要关注log中自然语言描述。
  - 通过对10个Java项目以及7个C#项目进行源代码分析，获得了6个有价值的发现。
  - 使用简单的IE方法更进一步展示了自动生成log中描述性文本的可能性。
  - 公开了数据集(https://github.com/logpai/LoggingDescriptions)
### Concepts
- `Logging`: in-house debuuging tools(e.g. debugger)经常在生产环境下无法使用，只能使用logging
  - 包含`descirption text`和`variables`
- `Logging Description`: 即logging中的自然语言描述。可分为三种(Finding 1)：
  - description for program operation(37.34%)
  - description for error condition(39.16%)
  - descriptionfor high-level code semantics(23.5%) 
### Challenges
- 目前没有完善的对于logging的Guide。
- 不同开发者保持一致的logging style非常困难。
- 尽管已有logging框架(MS的ULS，Apache log4net)，开发者仍然需要自己做logging决策(where to log, what to log)
- Yuan et al. 开发了 `logEnhancer`可以通过添加informative variables来增加logging语句，但是只注意于已有的statement而没有考虑到description text。
### Methods
- 实证方法分析项目logging的自然语言描述
  - Java项目来自Apache多于15个Commiter的项目，C#来自Github上超过1000 star的项目
  - `purpose` of logging:人工检查383个logging语句以及它们周围的代码片段
    - 从所有projects中随机抽样人工检查而得，Concepts中所记三种。
    - 使用`standard techniques`来计算sample的数量(383):5%`desired margin of error`, 95%`confidence level`, `data size`(82476所决定。参考文献`Determining sample size for research activities.`
- `repetitive usages` of certain `n-gram`: 
  - Logging Descriptions中是否有重复？
    - 通过构建n-grams language model来预测token，如果有重复，那么这个模型就会取得不错的效果。
      - 使用`Modified Kneser-Ney Smoothing`(软件领域常用的smoothing方法)来在Markov模型中对未见过的单词进行smoothing。
  - 跟common english corpora进行比较发现logging statement的重复n-gram现象更强。(Finding 2)
  - n-gram模型能否获得重复性地特征：对一个项目训练好n-gram模型后拿到另外一个项目上看效果，结果是效果并不好。(Finding 3)
  - 有很多n-gram是`locally endemic`，即只出现在一个源文件中，相比源代码的程度要高，而且common english中也没有这种现象。(Finding 4)可以利用该特性改善自动logging method, `caching mechanism`。
  - 非endemic的n-gram在不同的source file中分布是否均衡？使用`locality entropy`来衡量。结果是分布不均衡，即n-grams存在`locally specific`(Finding 5)
- 基于以上两点，研究自动生成logging description
  - 基于假设：相似的代码片段倾向于包含相似的logging descriptions
  - 基于IE实现：提取需要生成logging descirptions的代码片段，搜索corpus中最相似的代码片段，并使用其logging description。
    - 简单地将代码当作字符串，使用`Levenshein distance`来计算相似度
    - 两种窗口设置，logging statement前10行，前10行+后10行
### Evaluations
- BLEU-1平均35%，BLEU-4平均16.96%。
- 对于Java和C#项目的效果类似(局部性不同为什么效果还类似?)
- 实践证明只考虑前10行的代码片段效果更好，因为针对之后代码进行logging的情况较少
- 之前没有根据代码片段生成logging描述的研究，所以没有比较。只有根据代码生成总结性描述(code summarition)与之优点类似。
### 思考
- 提出一个新的领域的问题时，需要先用数据说明问题确实存在以及研究的必要性
- 提出了很多有趣的研究问题(RQ)，并得到了对应的Finding
- 对于logging可能有的用于格式化的特殊字符，比如[],()，：，等是怎么处理的？
- 可以通过抽象语法树等更复杂的模型对代码建模，以更好地计算代码间的相似度。
### Related Work
- Log Analysis
- `Logging Practice`
  - Characterizing logging practices in opensource software
- Improving Log
  - LogAdvior. Improving software diagnosability via log enhancement. 
  - `LogEnhancer`:添加重要的变量来增强已有的logging statements. Learning to Log: Helping Developers Make Informed Logging Decisions
- NLP in Software Engineering
  - study the characteristics of source code
  - `defect prediction`. On the "Naturalness" of Buggy Code
  - `code completion`. A Deep Neural Network Language Model with Contexts for Source Code.
  - `program synthesis`. SWIM: Synthesizing What I Mean: Code Search and Idiomatic Snippet Synthesis
  - `API recommendation`. 
    - Deep API learning.
    - Effective API recommendation without historical software repositories(ASE 2018)
    - API method recommendation without worrying about the task-API knowledge gap(ASE 2018) 
  - `identifier/method name suggestion`. 
    - Learning natural coding conventions.
    - Suggesting accurate method and class names. 

## Effective API recommendation without historical software repositories
### Topic: Developer Tools
### Motivation
### Concepts
### Challenges
### Evaluations
### 思考
### Related Work

## API method recommendation without worrying about the task-API knowledge gap
### Topic: Developer Tools
## Generating reusable web components from mockups
### Topic: Repair
## Datalog-based scalable semantic diffing of concurrent programs
### Topic: Code Differencing and Merging
## Experiences applying automated architecture analysis tool suites
### Topic: Experience Papers
## Automatically testing implementations of numerical abstract domains
### Topic: Experience Papers
## Continuous code quality: are we (really) doing that?
### Topic: New Ideas Papers
## node2defect: using network embedding to improve software defect prediction
### Topic: New Ideas Papers